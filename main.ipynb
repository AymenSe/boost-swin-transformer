{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# nb_dir = os.path.split(os.getcwd())\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.barlow_twins import SwinBarlowTwins\n",
    "from model.build_swin_vit import build_model\n",
    "from config import get_config\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full config saved to output\\config_swin_transformer_barlow_twins_cxr.json\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "os.makedirs(config.OUTPUT, exist_ok=True)\n",
    "\n",
    "seed = config.SEED\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "path = os.path.join(config.OUTPUT, f\"config_{config.NAME}.json\")\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(config.dump())\n",
    "\n",
    "print(f\"Full config saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sched import scheduler\n",
    "import wandb\n",
    "import torch\n",
    "from data.build_dataset import get_nih, get_chexpert\n",
    "import os\n",
    "from data.dataset import NIH_Dataset, CheX_Dataset\n",
    "from model.build_swin_vit import build_swin_vit\n",
    "from model.BoostSwinTransformer import BoostSwin\n",
    "from .utils import *\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import time\n",
    "from optimizer import get_optim\n",
    "from scheduler import get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from .train import train\n",
    "from .eval import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params):\n",
    "    with wandb.init(project=\"swin-twins\", entity=\"asekhri\", job_type=\"train\", config=params) as run:\n",
    "        config = wandb.config\n",
    "        os.makedirs(config.predictions , exist_ok=True)\n",
    "\n",
    "        if config.DATASET == \"NIH\":\n",
    "            train_loader, valid_loader, test_loader = get_nih(config, NIH_Dataset)\n",
    "        elif config.DATASET == \"chexpert\":\n",
    "            train_loader, valid_loader, test_loader = get_chexpert(config, CheX_Dataset)\n",
    "        else:\n",
    "            raise ValueError(\"Dataset not supported\")\n",
    "\n",
    "        # model\n",
    "        model = BoostSwin(config).to(config.DEVICE)\n",
    "        \n",
    "        # load pretrained\n",
    "        if config.PRETRAINED:\n",
    "            load_pretrained(config, model)\n",
    "\n",
    "        # optimizer        \n",
    "        optimizer = get_optim(config, model)\n",
    "        \n",
    "        # criterion\n",
    "        criterion = nn.CrossEntropyLoss().to(config.DEVICE)\n",
    "\n",
    "        # scheduler\n",
    "        if config.SCHEDULER_NAME:\n",
    "            lr_scheduler = get_scheduler(config, optimizer)\n",
    "        else:\n",
    "            lr_scheduler = None\n",
    "\n",
    "        # scaler\n",
    "        scaler = GradScaler(enabled=config.AMP_ENABLE)\n",
    "        \n",
    "        # Check if we have a checkpoint\n",
    "        best_auc = 0\n",
    "        if config.RESUME:\n",
    "            config.START_EPOCH, best_auc = load_checkpoint(config, model, optimizer, lr_scheduler, scaler)\n",
    "            print(f\"Resuming from epoch {config.START_EPOCH} with best auc {best_auc}\")\n",
    "\n",
    "        # Train artifacts\n",
    "        artifact = wandb.Artifact(\"proposed-method\", type=\"model\", description=\"boost swin T with SSL\", metadata=dict(config))\n",
    "        \n",
    "        for epoch in range(config.START_EPOCH, config.EPOCHS):\n",
    "            # Train the model for one epoch\n",
    "            train_loss, train_acc, train_auc = train(config, train_loader, model, criterion, optimizer, scheduler, scaler, epoch)\n",
    "\n",
    "            # validate the model for one epoch\n",
    "            valid_loss, valid_acc, valid_auc = validate(config, model, valid_loader, criterion, epoch)\n",
    "\n",
    "            if config.SCHEDULER_NAME:\n",
    "                lr_scheduler.step(valid_loss)\n",
    "            \n",
    "            # test the model for one epoch\n",
    "            test_loss, test_acc, test_auc = validate(config, model, test_loader, criterion, epoch)\n",
    "\n",
    "            # save checkpoint\n",
    "            save_checkpoint(config, model, optimizer, test_auc, lr_scheduler, scaler, epoch)\n",
    "\n",
    "            # save checkpoint if best\n",
    "            if test_auc > best_auc:\n",
    "                best_auc = test_auc\n",
    "                save_checkpoint(config, model, optimizer, test_auc, lr_scheduler, scaler, epoch, is_best=True)\n",
    "\n",
    "        # add  to wandb    \n",
    "        artifact.add_file(os.path.join(config.OUTPUT, 'checkpoint.pth'), name=\"ckp.pth\")\n",
    "        artifact.add_file(os.path.join(config.OUTPUT, 'model_best.pth'), name=\"best.pth\")\n",
    "        run.log_artifact(artifact)\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "629a1f200d627dc9f78053cb8498f06c4855dec7207b8b69c336b24456dfbb1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
